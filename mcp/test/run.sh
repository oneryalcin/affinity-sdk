#!/usr/bin/env bash
# Test runner for MCP tools - generated by mcp-bash scaffold test
# Usage: ./test/run.sh [--verbose] [--force]
set -euo pipefail

PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
export MCPBASH_PROJECT_ROOT="${PROJECT_ROOT}"

case "$(uname -s 2>/dev/null)" in
MINGW* | MSYS*)
	# Keep path conversion enabled so Windows-native jq/gojq can open temp files.
	unset MSYS2_ARG_CONV_EXCL
	;;
esac

# Locate mcp-bash binary
MCPBASH_BIN="${MCPBASH_BIN:-}"
if [[ -z "${MCPBASH_BIN}" ]] && command -v mcp-bash >/dev/null 2>&1; then
	MCPBASH_BIN="$(command -v mcp-bash)"
fi
if [[ -z "${MCPBASH_BIN}" ]] && [[ -n "${MCPBASH_HOME:-}" ]] && [[ -x "${MCPBASH_HOME}/bin/mcp-bash" ]]; then
	MCPBASH_BIN="${MCPBASH_HOME}/bin/mcp-bash"
fi
if [[ -z "${MCPBASH_BIN}" ]] && [[ -x "${PROJECT_ROOT}/../bin/mcp-bash" ]]; then
	MCPBASH_BIN="${PROJECT_ROOT}/../bin/mcp-bash"
fi
if [[ -z "${MCPBASH_BIN}" ]] && [[ -x "${PROJECT_ROOT}/bin/mcp-bash" ]]; then
	MCPBASH_BIN="${PROJECT_ROOT}/bin/mcp-bash"
fi
if [[ -z "${MCPBASH_BIN}" ]]; then
	printf 'mcp-bash not found; add to PATH or set MCPBASH_HOME.\n' >&2
	exit 1
fi

VERBOSE="${VERBOSE:-0}"
FORCE="${FORCE:-0}"

while [[ $# -gt 0 ]]; do
	case "$1" in
	--verbose | -v)
		VERBOSE=1
		shift
		;;
	--force | -f)
		FORCE=1
		shift
		;;
	*)
		break
		;;
	esac
done

passed=0
failed=0
skipped=0

# Colors (disabled if not a terminal)
RED=""
GREEN=""
YELLOW=""
RESET=""
if [[ -t 1 ]]; then
	RED="\033[0;31m"
	GREEN="\033[0;32m"
	YELLOW="\033[0;33m"
	RESET="\033[0m"
fi

run_test() {
	local name="$1"
	local args="$2"
	args="${args:-"{}"}"
	local description="${3:-}"

	if [[ -n "${description}" ]]; then
		printf "  %s (%s)... " "${name}" "${description}"
	else
		printf "  %s... " "${name}"
	fi

	local output
	if [[ "${VERBOSE}" == "1" ]]; then
		if "${MCPBASH_BIN}" run-tool "${name}" --args "${args}" --verbose; then
			printf '%sPASS%s\n' "${GREEN}" "${RESET}"
			((++passed)) || true
		else
			printf '%sFAIL%s\n' "${RED}" "${RESET}"
			((++failed)) || true
		fi
	else
		if output=$("${MCPBASH_BIN}" run-tool "${name}" --args "${args}" 2>&1); then
			printf '%sPASS%s\n' "${GREEN}" "${RESET}"
			((++passed)) || true
		else
			printf '%sFAIL%s\n' "${RED}" "${RESET}"
			if [[ -n "${output}" ]]; then
				printf "    Output: %s\n" "${output}" >&2
			fi
			((++failed)) || true
		fi
	fi
}

run_dry_run() {
	local name="$1"
	local args="$2"
	args="${args:-"{}"}"

	printf "  %s (dry-run)... " "${name}"

	local output
	local -a extra_flags=()
	if [[ "${VERBOSE}" == "1" ]]; then
		extra_flags+=(--verbose)
	fi

	if output=$("${MCPBASH_BIN}" run-tool "${name}" --args "${args}" --dry-run "${extra_flags[@]}" 2>&1); then
		printf '%sPASS%s\n' "${GREEN}" "${RESET}"
		((++passed)) || true
	else
		printf '%sFAIL%s\n' "${RED}" "${RESET}"
		if [[ -n "${output}" ]]; then
			printf "    Output: %s\n" "${output}" >&2
		fi
		((++failed)) || true
	fi
}

skip_test() {
	local name="$1"
	local reason="${2:-}"

	printf "  %s... ${YELLOW}SKIP${RESET}" "${name}"
	if [[ -n "${reason}" ]]; then
		printf " (%s)" "${reason}"
	fi
	printf "\n"
	((++skipped)) || true
}

# Discover and validate tools exist
printf "Discovering tools...\n"
if ! "${MCPBASH_BIN}" validate --project-root "${PROJECT_ROOT}" >/dev/null 2>&1; then
	printf '%sError: Project validation failed. Run '\''mcp-bash validate'\'' for details.%s\n' "${RED}" "${RESET}" >&2
	if [[ "${FORCE}" != "1" ]]; then
		printf "Use --force to run tests anyway.\n" >&2
		exit 1
	fi
	printf '%sContinuing anyway (--force)...%s\n' "${YELLOW}" "${RESET}" >&2
fi

printf "\nRunning tests...\n"

# ============================================================================
# XAFFINITY MCP TOOL TESTS
# ============================================================================
# These tests require a configured Affinity API key.
# Run: xaffinity config check-key to verify.
# ============================================================================

# Check if API is configured
if ! xaffinity config check-key --json >/dev/null 2>&1; then
    printf '%sWarning: Affinity API not configured. Some tests will be skipped.%s\n' "${YELLOW}" "${RESET}" >&2
    API_CONFIGURED=0
else
    API_CONFIGURED=1
fi

# Load test configuration from .env.test (not committed)
# Copy .env.test.example to .env.test and configure your test entity IDs
TEST_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
if [[ -f "${TEST_DIR}/.env.test" ]]; then
    # shellcheck disable=SC1091
    source "${TEST_DIR}/.env.test"
fi

# Test IDs - must be set in .env.test or environment variables
TEST_PERSON_ID="${TEST_PERSON_ID:-}"
TEST_COMPANY_ID="${TEST_COMPANY_ID:-}"
TEST_LIST_ID="${TEST_LIST_ID:-}"

printf "\n--- Dry-run validation (no API calls) ---\n"

# Dry-run tests validate args and metadata without calling API
# Read-only tools
run_dry_run "find-entities" '{"query":"test"}'
run_dry_run "find-lists" '{}'
run_dry_run "get-entity-dossier" '{"entityId":"123","entityType":"person"}'
run_dry_run "get-relationship-insights" '{"targetId":"123"}'
run_dry_run "get-interactions" '{"entityId":"123","entityType":"person"}'
run_dry_run "get-status-timeline" '{"entityId":"123","entityType":"person"}'
run_dry_run "get-list-workflow-config" '{"listId":"123"}'
run_dry_run "get-workflow-view" '{"listId":"123"}'
run_dry_run "resolve-workflow-item" '{"listId":"123","query":"test"}'
run_dry_run "read-xaffinity-resource" '{"uri":"xaffinity://person/123"}'

# Write tools (dry-run only - validates args without executing)
run_dry_run "add-note" '{"entityId":"123","entityType":"person","content":"test"}'
run_dry_run "log-interaction" '{"entityId":"123","entityType":"person","type":"meeting"}'
run_dry_run "set-workflow-status" '{"listId":"123","entityId":"456","entityType":"person","status":"Active"}'
run_dry_run "update-workflow-fields" '{"listId":"123","entityId":"456","entityType":"person","fields":{}}'

if [[ "${API_CONFIGURED}" != "1" ]]; then
    skip_test "find-entities (live)" "API not configured"
    skip_test "find-lists (live)" "API not configured"
    skip_test "get-entity-dossier (live)" "API not configured"
    skip_test "get-relationship-insights (live)" "API not configured"
elif [[ "${SKIP_LIVE:-0}" == "1" ]]; then
    skip_test "live tests" "SKIP_LIVE=1"
else
    printf "\n--- Live API tests (READ-ONLY) ---\n"

    # Entity search tests (read-only)
    run_test "find-entities" '{"query":"test","types":["person","company"],"limit":5}' "search persons and companies"
    run_test "find-lists" '{}' "list all lists"

    # Entity dossier tests (requires valid person ID from .env.test)
    if [[ -n "${TEST_PERSON_ID}" ]]; then
        run_test "get-entity-dossier" '{"entityId":"'"${TEST_PERSON_ID}"'","entityType":"person","includeInteractions":true,"includeLists":true}' "person dossier"
        run_test "get-relationship-insights" '{"targetId":"'"${TEST_PERSON_ID}"'"}' "relationship insights"
        run_test "get-interactions" '{"entityId":"'"${TEST_PERSON_ID}"'","entityType":"person","limit":5}' "person interactions"
    else
        skip_test "get-entity-dossier (person)" "set TEST_PERSON_ID in .env.test"
        skip_test "get-relationship-insights" "set TEST_PERSON_ID in .env.test"
        skip_test "get-interactions (person)" "set TEST_PERSON_ID in .env.test"
    fi

    # Company tests - skipped due to V2 API ID mismatch with search results
    # TODO: Fix company ID resolution between search and get APIs
    skip_test "get-entity-dossier (company)" "V2 API ID mismatch"

    # List-based tests (requires valid list ID from .env.test)
    if [[ -n "${TEST_LIST_ID}" ]]; then
        run_test "get-list-workflow-config" '{"listId":"'"${TEST_LIST_ID}"'"}' "workflow config"
        run_test "get-workflow-view" '{"listId":"'"${TEST_LIST_ID}"'","limit":5}' "workflow view"
    else
        skip_test "get-list-workflow-config" "set TEST_LIST_ID in .env.test"
        skip_test "get-workflow-view" "set TEST_LIST_ID in .env.test"
    fi
fi

# ============================================================================
# END OF TESTS
# ============================================================================

printf "\n"
printf "Results: ${GREEN}%d passed${RESET}, ${RED}%d failed${RESET}" "${passed}" "${failed}"
if [[ "${skipped}" -gt 0 ]]; then
	printf ", ${YELLOW}%d skipped${RESET}" "${skipped}"
fi
printf "\n"

[[ "${failed}" -eq 0 ]] || exit 1
